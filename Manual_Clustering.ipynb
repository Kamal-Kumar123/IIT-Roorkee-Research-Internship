{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# datasets:\n",
        "# Here we performed manual clustering calculations over different excel files::\n",
        "# dataset Path: \"/content/drive/MyDrive/Transformer_Review/third_work/results/{Dataset_name}/{search_technique_captions}.ods\"\n",
        "# Use it 6 times because we have total 3 datasets and 2 search techniques. so, overall 6 files are there.\n",
        "# dataset link: https://drive.google.com/drive/folders/1doSn3PxWoks5yA9vLRWUcObkpOotxDJp?usp=sharing"
      ],
      "metadata": {
        "id": "X20ghnmRW8dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install odfpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfJOF3nqO_iv",
        "outputId": "7ee3394c-bd1e-4581-99d4-970548758d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting odfpy\n",
            "  Downloading odfpy-1.4.1.tar.gz (717 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.0/717.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from odfpy) (0.7.1)\n",
            "Building wheels for collected packages: odfpy\n",
            "  Building wheel for odfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odfpy: filename=odfpy-1.4.1-py2.py3-none-any.whl size=160672 sha256=239cd78ccf9e25590cf49256dd1a0b50fc6e5dbdf345d0083406a7e1b65187b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/1d/c8/8c29be1d73ca42d15977c75193d9f39a98499413c2838ac54c\n",
            "Successfully built odfpy\n",
            "Installing collected packages: odfpy\n",
            "Successfully installed odfpy-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG9Gf3iPPMEm",
        "outputId": "069bde9c-9593-402f-80ea-bc4073fe8ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iAseErPOcHA"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import gmean\n",
        "\n",
        "# Function to initialize centroids\n",
        "def initialize_centroids(data, n_clusters=3, random_state=42):\n",
        "    \"\"\"\n",
        "    Initialize centroids using K-Means++ initialization.\n",
        "    \"\"\"\n",
        "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=1, max_iter=1, random_state=random_state)\n",
        "    kmeans.fit(data)  # Perform a single iteration to initialize centroids\n",
        "    return kmeans.cluster_centers_\n",
        "\n",
        "# Function to perform manual K-means clustering\n",
        "def kmeans_manual(data, centroids, max_iter=300, tol=1e-4):\n",
        "    \"\"\"\n",
        "    Perform manual K-Means clustering given initial centroids.\n",
        "    \"\"\"\n",
        "    for i in range(max_iter):\n",
        "        # Calculate distance matrix\n",
        "        distances = np.linalg.norm(data.values[:, np.newaxis, :] - centroids, axis=2)\n",
        "        # Assign points to nearest centroids\n",
        "        cluster_assignments = np.argmin(distances, axis=1)\n",
        "        # Recalculate centroids\n",
        "        new_centroids = np.array([data.iloc[cluster_assignments == j].mean(axis=0) for j in range(centroids.shape[0])])\n",
        "        # Check for convergence\n",
        "        if np.all(np.linalg.norm(new_centroids - centroids, axis=1) < tol):\n",
        "            print(f\"Converged after {i+1} iterations\")\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "    return centroids, distances, cluster_assignments\n",
        "\n",
        "# Function to compute geometric mean of centroids\n",
        "def get_geometric_mean(centroids):\n",
        "    \"\"\"\n",
        "    Calculate the geometric mean for each cluster centroid.\n",
        "    \"\"\"\n",
        "    gm_values = {}\n",
        "    for i, centroid in enumerate(centroids):\n",
        "        gm = gmean(centroid)\n",
        "        gm_values[i] = gm\n",
        "    return gm_values\n",
        "\n",
        "# Function to validate clustering\n",
        "def validate_clustering(data, centroids, distances, clusters):\n",
        "    \"\"\"\n",
        "    Cross-check and validate clustering assignments.\n",
        "    \"\"\"\n",
        "    # Check cluster sizes\n",
        "    cluster_sizes = {i: np.sum(clusters == i) for i in range(centroids.shape[0])}\n",
        "    print(\"Cluster Sizes:\", cluster_sizes)\n",
        "\n",
        "    # Calculate geometric means of centroids\n",
        "    gm_values = get_geometric_mean(centroids)\n",
        "    print(\"Geometric Mean of Centroids:\", gm_values)\n",
        "\n",
        "    # Examine distances within each cluster\n",
        "    for i in range(centroids.shape[0]):\n",
        "        cluster_distances = distances[clusters == i, i]\n",
        "        print(f\"Cluster {i} - Average Distance to Centroid: {np.mean(cluster_distances):.4f}\")\n",
        "        print(f\"Cluster {i} - Max Distance to Centroid: {np.max(cluster_distances):.4f}\")\n",
        "\n",
        "    # Verify assignment consistency\n",
        "    sorted_clusters = sorted(gm_values, key=gm_values.get, reverse=True)\n",
        "    print(\"Clusters ranked by Geometric Mean (Good -> Bad):\", sorted_clusters)\n",
        "\n",
        "    return cluster_sizes, gm_values, sorted_clusters\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Execution\n",
        "path ='/content/drive/MyDrive/Transformer_Review/third_work/results/UCM/greedy_captions.ods'\n",
        "data = pd.read_excel(path , engine='odf', index_col=0)\n",
        "\n",
        "# Normalize CIDEr score\n",
        "data['CIDEr'] = data['CIDEr'] / 5\n",
        "\n",
        "# Initialize centroids\n",
        "initial_centroids = initialize_centroids(data.values, n_clusters=3)\n",
        "print(\"Initialized Centroids:\\n\", initial_centroids)\n",
        "\n",
        "# Perform manual K-means clustering\n",
        "final_centroids, distances, clusters = kmeans_manual(data, initial_centroids)\n",
        "print(\"Final Centroids:\\n\", final_centroids)\n",
        "\n",
        "# Validate the clustering\n",
        "cluster_sizes, gm_values, sorted_clusters = validate_clustering(data, final_centroids, distances, clusters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-BZuN1gPxGe",
        "outputId": "f4306633-6120-425a-83cc-35ee8d7b1055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Centroids:\n",
            " [[0.79682    0.721      0.66326    0.61324    0.4197     0.75604\n",
            "  0.632956  ]\n",
            " [0.835725   0.770325   0.7152     0.66505    0.450775   0.7975\n",
            "  0.692625  ]\n",
            " [0.82503333 0.7501     0.69026667 0.63823333 0.43666667 0.7783\n",
            "  0.66923333]]\n",
            "Converged after 3 iterations\n",
            "Final Centroids:\n",
            " [[0.782      0.7023     0.64215    0.59075    0.40925    0.7391\n",
            "  0.60785   ]\n",
            " [0.835725   0.770325   0.7152     0.66505    0.450775   0.7975\n",
            "  0.692625  ]\n",
            " [0.81586667 0.74178333 0.6838     0.63323333 0.43166667 0.77281667\n",
            "  0.65946333]]\n",
            "Cluster Sizes: {0: 2, 1: 4, 2: 6}\n",
            "Geometric Mean of Centroids: {0: 0.6274921232246911, 1: 0.6923336007750995, 2: 0.665230434810189}\n",
            "Cluster 0 - Average Distance to Centroid: 0.0191\n",
            "Cluster 0 - Max Distance to Centroid: 0.0191\n",
            "Cluster 1 - Average Distance to Centroid: 0.0243\n",
            "Cluster 1 - Max Distance to Centroid: 0.0324\n",
            "Cluster 2 - Average Distance to Centroid: 0.0238\n",
            "Cluster 2 - Max Distance to Centroid: 0.0410\n",
            "Clusters ranked by Geometric Mean (Good -> Bad): [1, 2, 0]\n"
          ]
        }
      ]
    }
  ]
}